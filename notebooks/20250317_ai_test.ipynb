{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gemini API ã«ã‚ˆã‚‹å¿œç­”ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ\n",
    "\n",
    "- https://aistudio.google.com/apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY=os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ã„AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã‚’å®ˆã£ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚\n",
    "- ã‚ãªãŸã®è³ªå•ã«ã¯ã˜ã˜ã„ã®å£èª¿ã§ç­”ãˆã‚‹ã“ã¨\n",
    "è³ªå•: {question}\n",
    "\"\"\"\n",
    "\n",
    "def chat_with_gemini(user_input):\n",
    "    prompt = PROMPT_TEMPLATE.format(question=user_input)\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "print(chat_with_gemini(\"è³¢è€…ã®çŸ³ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings\n",
    "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# APIã‚­ãƒ¼è¨­å®š\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "\n",
    "# 1.ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "# 2.çŸ¥è­˜ãƒ™ãƒ¼ã‚¹\n",
    "texts = [\n",
    "    \"AIï¼ˆäººå·¥çŸ¥èƒ½ï¼‰ã¯ã€æ©Ÿæ¢°ãŒäººé–“ã®ã‚ˆã†ã«å­¦ç¿’ãƒ»åˆ¤æ–­ã™ã‚‹æŠ€è¡“ã®ã“ã¨ã§ã™ã€‚\",\n",
    "    \"æ©Ÿæ¢°å­¦ç¿’ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ã³ã€äºˆæ¸¬ã‚„åˆ¤æ–­ã‚’è¡Œã†æŠ€è¡“ã§ã™ã€‚\",\n",
    "    \"LLMï¼ˆå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰ã¯ã€å¤šé‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦è¨“ç·´ã•ã‚ŒãŸè‡ªç„¶è¨€èªå‡¦ç†ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚\",\n",
    "    \"Geminiã¯GoogleãŒé–‹ç™ºã—ãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã§ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªã‚¿ã‚¹ã‚¯ã«å¯¾å¿œå¯èƒ½ã§ã™ã€‚\",\n",
    "]\n",
    "\n",
    "metadata = [\n",
    "    {\"source\": \"AIã®åŸºæœ¬\"},\n",
    "    {\"source\": \"æ©Ÿæ¢°å­¦ç¿’\"},\n",
    "    {\"source\": \"LLM\"},\n",
    "    {\"source\": \"Gemini\"},\n",
    "]\n",
    "\n",
    "documents = [Document(page_content=text, metadata=meta) for text, meta in zip(texts, metadata)]\n",
    "\n",
    "# 3.FAISSã‚’ä½¿ã£ã¦ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆ\n",
    "vectorstore = FAISS.from_texts(texts, embedding=embedding_model, metadatas=metadata)\n",
    "\n",
    "# 4.Geminiã®ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®š\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.5)\n",
    "\n",
    "# 5.ä¼šè©±å±¥æ­´ã‚’ä¿æŒã™ã‚‹ãŸã‚ã®ãƒ¡ãƒ¢ãƒªè¨­å®š\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# 6.æ¤œç´¢æ©Ÿèƒ½ä»˜ããƒãƒ£ãƒƒãƒˆãƒã‚§ãƒ¼ãƒ³ã‚’æ§‹ç¯‰\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm, retriever=vectorstore.as_retriever(), memory=memory\n",
    ")\n",
    "\n",
    "# 7.é–¢æ•°ã‚’ä½œæˆ\n",
    "def chat_with_gemini(user_input):\n",
    "    response = qa_chain.invoke({\"question\": user_input})\n",
    "    return response[\"answer\"]\n",
    "\n",
    "# 8.å®Ÿè¡Œ\n",
    "print(chat_with_gemini(\"AIã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings\n",
    "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# APIã‚­ãƒ¼è¨­å®š\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "\n",
    "# 1. ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "# 2. çŸ¥è­˜ãƒ™ãƒ¼ã‚¹\n",
    "texts = [\n",
    "    \"AIï¼ˆäººå·¥çŸ¥èƒ½ï¼‰ã¯ã€æ©Ÿæ¢°ãŒäººé–“ã®ã‚ˆã†ã«å­¦ç¿’ãƒ»åˆ¤æ–­ã™ã‚‹æŠ€è¡“ã®ã“ã¨ã§ã™ã€‚\",\n",
    "    \"æ©Ÿæ¢°å­¦ç¿’ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ã³ã€äºˆæ¸¬ã‚„åˆ¤æ–­ã‚’è¡Œã†æŠ€è¡“ã§ã™ã€‚\",\n",
    "    \"LLMï¼ˆå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰ã¯ã€å¤šé‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦è¨“ç·´ã•ã‚ŒãŸè‡ªç„¶è¨€èªå‡¦ç†ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚\",\n",
    "    \"Geminiã¯GoogleãŒé–‹ç™ºã—ãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã§ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªã‚¿ã‚¹ã‚¯ã«å¯¾å¿œå¯èƒ½ã§ã™ã€‚\",\n",
    "]\n",
    "\n",
    "metadata = [\n",
    "    {\"source\": \"AIã®åŸºæœ¬\"},\n",
    "    {\"source\": \"æ©Ÿæ¢°å­¦ç¿’\"},\n",
    "    {\"source\": \"LLM\"},\n",
    "    {\"source\": \"Gemini\"},\n",
    "]\n",
    "\n",
    "documents = [Document(page_content=text, metadata=meta) for text, meta in zip(texts, metadata)]\n",
    "\n",
    "# 3. FAISS ã‚’ä½¿ã£ã¦ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆ\n",
    "vectorstore = FAISS.from_texts(texts, embedding=embedding_model, metadatas=metadata)\n",
    "\n",
    "# 4. Gemini ã®ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®š\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.5)\n",
    "\n",
    "# 5. ä¼šè©±å±¥æ­´ã‚’ä¿æŒã™ã‚‹ãŸã‚ã®ãƒ¡ãƒ¢ãƒªè¨­å®š\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# 6. æ¤œç´¢æ©Ÿèƒ½ä»˜ããƒãƒ£ãƒƒãƒˆãƒã‚§ãƒ¼ãƒ³ã‚’æ§‹ç¯‰\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm, retriever=vectorstore.as_retriever(), memory=memory\n",
    ")\n",
    "\n",
    "# 7. é–¢æ•°ã‚’ä½œæˆ\n",
    "def chat_with_gemini(user_input):\n",
    "    # ğŸ”¹ **é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ¤œç´¢çµæœï¼‰ã‚’å–å¾—**\n",
    "    relevant_docs = vectorstore.as_retriever().get_relevant_documents(user_input)\n",
    "\n",
    "    # ğŸ”¹ **å–å¾—ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º**\n",
    "    print(\"\\nğŸ” é–¢é€£ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ¤œç´¢çµæœï¼‰ï¼š\")\n",
    "    for idx, doc in enumerate(relevant_docs):\n",
    "        print(f\"{idx+1}. {doc.page_content}  [Source: {doc.metadata.get('source', 'ä¸æ˜')}]\")\n",
    "\n",
    "    # ğŸ”¹ **Gemini ã«è³ªå•ã‚’é€ä¿¡**\n",
    "    response = qa_chain.invoke({\"question\": user_input})\n",
    "\n",
    "    return response[\"answer\"]\n",
    "\n",
    "# 8. å®Ÿè¡Œ\n",
    "print(\"\\nğŸ¤– Gemini ã®å›ç­”:\")\n",
    "print(chat_with_gemini(\"AIã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
